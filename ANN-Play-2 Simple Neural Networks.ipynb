{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network Play 2: Simple Neural Networks\n",
    "\n",
    "Part one can be found [here](http://nbviewer.ipython.org/github/Ogaday/ml-play/blob/master/ANN-Play%2001%20Perceptrons.ipynb) and is part of a series on github [here](https://github.com/Ogaday/ml-play). Sources are inlcuded in the first notebook.\n",
    "\n",
    "This chapter will be focussed on building and activating simple neural networks.\n",
    "\n",
    "## A simple neural network\n",
    "\n",
    "I will try a graphical representation of the neural network. A graph is often defined by a triple: $(V, E, \\varepsilon)$ where $V$ is the set of vertices, $E$ is the set of edges and $\\varepsilon$ is the endpoint map $\\varepsilon:E\\to P_1\\{V\\}\\cup P_2\\{V\\}$. (A mapping of edges to the union of the power set of one and the power set of two of the set of vertices).\n",
    "\n",
    "In this case, the graph is weighted, so we introduce a metric map $\\mu$ such that $\\mu: E \\to \\mathbb R$, where $\\mathbb R$ is the set of real values and the mapping denotes of the weight on each edge. Furthermore, this graph should be loop free, so in fact we can simplify $\\varepsilon$ to $\\varepsilon:E\\to P_2\\{V\\}$ and as this graph is directed, order of the elements in $p_i\\member$ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
